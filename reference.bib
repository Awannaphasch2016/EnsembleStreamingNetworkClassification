@article{barrosSurveyEmbeddingDynamic2021,
  title           = {A {{Survey}} on {{Embedding Dynamic Graphs}}},
  author          = {Barros, Claudio D. T. and Mendon{\c c}a, Matheus R. F. and
                  Vieira, Alex B. and Ziviani, Artur},
  year            = 2021,
  month           = jan,
  journal         = {arXiv:2101.01229 [cs]},
  eprint          = {2101.01229},
  eprinttype      = {arxiv},
  primaryclass    = {cs},
  abstract        = {Embedding static graphs in low-dimensional vector spaces
                  plays a key role in network analytics and inference,
                  supporting applications like node classification, link
                  prediction, and graph visualization. However, many real-world
                  networks present dynamic behavior, including topological
                  evolution, feature evolution, and diffusion. Therefore,
                  several methods for embedding dynamic graphs have been
                  proposed to learn network representations over time, facing
                  novel challenges, such as time-domain modeling, temporal
                  features to be captured, and the temporal granularity to be
                  embedded. In this survey, we overview dynamic graph embedding,
                  discussing its fundamentals and the recent advances developed
                  so far. We introduce the formal definition of dynamic graph
                  embedding, focusing on the problem setting and introducing a
                  novel taxonomy for dynamic graph embedding input and output.
                  We further explore different dynamic behaviors that may be
                  encompassed by embeddings, classifying by topological
                  evolution, feature evolution, and processes on networks.
                  Afterward, we describe existing techniques and propose a
                  taxonomy for dynamic graph embedding techniques based on
                  algorithmic approaches, from matrix and tensor factorization
                  to deep learning, random walks, and temporal point processes.
                  We also elucidate main applications, including dynamic link
                  prediction, anomaly detection, and diffusion prediction, and
                  we further state some promising research directions in the
                  area.},
  archiveprefix   = {arXiv},
  keywords        = {37E25 (Primary) 68T30; 05C62; 58D10
                  (Secondary),A.1,Computer Science - Artificial
                  Intelligence,Computer Science - Machine Learning,I.2.6},
  note            = {Comment: 40 pages, 10 figures},
  url={https://dl.acm.org/doi/pdf/10.1145/3483595},
  file            = {/mnt/c/Users/terng/Zotero/storage/9HFG3744/Barros et
                  al_2021_A Survey on Embedding Dynamic Graphs.pdf},
}


@article{holme2012temporal,
  title           = {Temporal networks},
  author          = {Holme, Petter and Saram{\"a}ki, Jari},
  journal         = {Physics reports},
  volume          = 519,
  number          = 3,
  pages           = {97--125},
  year            = 2012,
  publisher       = {Elsevier},
  file            = {~/org/papers/temporal-networks.pdf},
}


@article{kazemiRepresentationLearningDynamica,
  title           = {Representation Learning for Dynamic Graphs A Survey},
  author          = {Kazemi, Seyed Mehran and Goel, Rishab and Jain, Kshitij and
                  Kobyzev, Ivan and Sethi, Akshay and Forsyth, Peter and
                  Poupart, Pascal},
  pages           = 73,
  abstract        = {Graphs arise naturally in many real-world applications
                  including social networks, recommender systems, ontologies,
                  biology, and computational finance. Traditionally, machine
                  learning models for graphs have been mostly designed for
                  static graphs. However, many applications involve evolving
                  graphs. This introduces important challenges for learning and
                  inference since nodes, attributes, and edges change over time.
                  In this survey, we review the recent advances in
                  representation learning for dynamic graphs, including dynamic
                  knowledge graphs. We describe existing models from an
                  encoder-decoder perspective, categorize these encoders and
                  decoders based on the techniques they employ, and analyze the
                  approaches in each category. We also review several prominent
                  applications and widely used datasets and highlight directions
                  for future research.},
  langid          = {english},
  url = {https://jmlr.org/papers/volume21/19-447/19-447.pdf}
  file            = {~/org/papers/Representation Learning for Dynamic Graphs A
                  Survey.pdf},
}

@article{kivela2014multilayer,
  title           = {Multilayer networks},
  author          = {Kivel{\"a}, Mikko and Arenas, Alex and Barthelemy, Marc and
                  Gleeson, James P and Moreno, Yamir and Porter, Mason A},
  journal         = {Journal of complex networks},
  volume          = 2,
  number          = 3,
  pages           = {203--271},
  year            = 2014,
  publisher       = {Oxford University Press}
}

@article{skarding2021benchmarking,
  title           = {Benchmarking Graph Neural Networks on Dynamic Link
                  Prediction},
  author          = {skarding, Joakim and Hellmich, Matthew and Gabrys, Bogdan
                  and Musial-Gabrys, Katarzyna},
  year            = 2021,
}

@article{skardingFoundationsModelingDynamic2021,
  title           = {Foundations and {{Modeling}} of {{Dynamic Networks Using
                  Dynamic Graph Neural Networks}}: {{A Survey}}},
  shorttitle      = {Foundations and {{Modeling}} of {{Dynamic Networks Using
                  Dynamic Graph Neural Networks}}},
  author          = {Skarding, Joakim and Gabrys, Bogdan and Musial, Katarzyna},
  year            = 2021,
  journal         = {IEEE Access},
  volume          = 9,
  pages           = {79143--79168},
  issn            = {2169-3536},
  doi             = {10.1109/ACCESS.2021.3082932},
  abstract        = {Dynamic networks are used in a wide range of fields,
                  including social network analysis, recommender systems and
                  epidemiology. Representing complex networks as structures
                  changing over time allow network models to leverage not only
                  structural but also temporal patterns. However, as dynamic
                  network literature stems from diverse fields and makes use of
                  inconsistent terminology, it is challenging to navigate.
                  Meanwhile, graph neural networks (GNNs) have gained a lot of
                  attention in recent years for their ability to perform well on
                  a range of network science tasks, such as link prediction and
                  node classification. Despite the popularity of graph neural
                  networks and the proven benefits of dynamic network models,
                  there has been little focus on graph neural networks for
                  dynamic networks. To address the challenges resulting from the
                  fact that this research crosses diverse fields as well as to
                  survey dynamic graph neural networks, this work is split into
                  two main parts. First, to address the ambiguity of the dynamic
                  network terminology we establish a foundation of dynamic
                  networks with consistent, detailed terminology and notation.
                  Second, we present a comprehensive survey of dynamic graph
                  neural network models using the proposed terminology.},
  langid          = {english},
  file            = {C\:\\Users\\terng\\Zotero\\storage\\XQJ8XKNM\\Skarding et
                  al. - 2021 - Foundations and Modeling of Dynamic Networks
                  Using.pdf},
}

@inproceedings{tian2021self,
  title           = {Self-supervised Representation Learning on Dynamic Graphs},
  author          = {Tian, Sheng and Wu, Ruofan and Shi, Leilei and Zhu, Liang
                  and Xiong, Tao},
  booktitle       = {Proceedings of the 30th ACM International Conference on
                  Information \& Knowledge Management},
  pages           = {1814--1823},
  year            = 2021,
  file            = {/home/awannaphasch2016/org/papers/self-supervised-representation-learning-on-dynamic-graphs.pdf},
}

@article{rossi2020temporal,
  title={Temporal graph networks for deep learning on dynamic graphs},
  author={Rossi, Emanuele and Chamberlain, Ben and Frasca, Fabrizio and Eynard, Davide and Monti, Federico and Bronstein, Michael},
  journal={arXiv preprint arXiv:2006.10637},
  year={2020},
  file = {/home/awannaphasch2016/org/papers/temporal-graph-network-for-deep-learning-on-dynamic-graphs.pdf}
}

@inproceedings{trivedi2019dyrep,
  title={Dyrep: Learning representations over dynamic graphs},
  author={Trivedi, Rakshit and Farajtabar, Mehrdad and Biswal, Prasenjeet and Zha, Hongyuan},
  booktitle={International conference on learning representations},
  year={2019},
  file = {/home/awannaphasch2016/org/papers/dyrep_learning_representations.pdf}
}

@article{kapoor2020examining,
  title={Examining covid-19 forecasting using spatio-temporal graph neural networks},
  author={Kapoor, Amol and Ben, Xue and Liu, Luyang and Perozzi, Bryan and Barnes, Matt and Blais, Martin and O'Banion, Shawn},
  journal={arXiv preprint arXiv:2007.03113},
  year={2020},
  url={https://arxiv.org/pdf/2007.03113.pdf},
  file = {/home/awannaphasch2016/org/papers/Examining-covid-19-forecating-using-spatio-temporal-graph-neural-network.pdf}
}

@inproceedings{wijayanto2018learning,
  title={Learning adaptive graph protection strategy on dynamic networks via reinforcement learning},
  author={Wijayanto, Arie Wahyu and Murata, Tsuyoshi},
  booktitle={2018 IEEE/WIC/ACM International Conference on Web Intelligence (WI)},
  pages={534--539},
  year={2018},
  organization={IEEE},
  file = {/home/awannaphasch2016/org/papers/learning-adaptive-graph-protection-strategy-on-dynamic-networks-via-reinforcement-learning.pdf}
}

@inproceedings{meirom2021controlling,
  title={Controlling graph dynamics with reinforcement learning and graph neural networks},
  author={Meirom, Eli and Maron, Haggai and Mannor, Shie and Chechik, Gal},
  booktitle={International Conference on Machine Learning},
  pages={7565--7577},
  year={2021},
  organization={PMLR},
  file={/home/awannaphasch2016/org/papers/ controlling-graph-dynamics-with-reinforcement-learning-and-graph-neural-networks.pdf}
}

@article{wijayanto2019effective,
  title={Effective and scalable methods for graph protection strategies against epidemics on dynamic networks},
  author={Wijayanto, Arie Wahyu and Murata, Tsuyoshi},
  journal={Applied Network Science},
  volume={4},
  number={1},
  pages={1--31},
  year={2019},
  publisher={SpringerOpen},
  file={/home/awannaphasch2016/org/papers/effective-and-scalable-methods-for-graph-protection-strategies-against-epidemics-on-dynamic-networks.pdf}
}


@article{yuanSurveyTrafficPrediction2021,
  title = {A {{Survey}} of {{Traffic Prediction}}: From {{Spatio-Temporal Data}} to {{Intelligent Transportation}}},
  shorttitle = {A {{Survey}} of {{Traffic Prediction}}},
  author = {Yuan, Haitao and Li, Guoliang},
  year = {2021},
  month = mar,
  journal = {Data Science and Engineering},
  volume = {6},
  number = {1},
  pages = {63--85},
  issn = {2364-1541},
  doi = {10.1007/s41019-020-00151-z},
  abstract = {Intelligent transportation (e.g., intelligent traffic light) makes our travel more convenient and efficient. With the development of mobile Internet and position technologies, it is reasonable to collect spatio-temporal data and then leverage these data to achieve the goal of intelligent transportation, and here, traffic prediction plays an important role. In this paper, we provide a comprehensive survey on traffic prediction, which is from the spatio-temporal data layer to the intelligent transportation application layer. At first, we split the whole research scope into four parts from bottom to up, where the four parts are, respectively, spatio-temporal data, preprocessing, traffic prediction and traffic application. Later, we review existing work on the four parts. First, we summarize traffic data into five types according to their difference on spatial and temporal dimensions. Second, we focus on four significant data preprocessing techniques: map-matching, data cleaning, data storage and data compression. Third, we focus on three kinds of traffic prediction problems (i.e., classification, generation and estimation/forecasting). In particular, we summarize the challenges and discuss how existing methods address these challenges. Fourth, we list five typical traffic applications. Lastly, we provide emerging research challenges and opportunities. We believe that the survey can help the partitioners to understand existing traffic prediction problems and methods, which can further encourage them to solve their intelligent transportation applications.},
  langid = {english},
  file = {C\:\\Users\\terng\\Zotero\\storage\\SKDX4KH9\\Yuan_Li_2021_A Survey of Traffic Prediction.pdf}
}

@article{cai2022temporal,
  title={Temporal Knowledge Graph Completion: A Survey},
  author={Cai, Borui and Xiang, Yong and Gao, Longxiang and Zhang, He and Li, Yunfeng and Li, Jianxin},
  journal={arXiv preprint arXiv:2201.08236},
  year={2022},
  file={/home/awannaphasch2016/org/papers/temporal-knowledge-graph-completion-a-survey.pdf}
}

@inproceedings{junuthula2016evaluating,
  title={Evaluating link prediction accuracy in dynamic networks with added and removed edges},
  author={Junuthula, Ruthwik R and Xu, Kevin S and Devabhaktuni, Vijay K},
  booktitle={2016 IEEE international conferences on big data and cloud computing (BDCloud), social computing and networking (SocialCom), sustainable computing and communications (SustainCom)(BDCloud-SocialCom-SustainCom)},
  pages={377--384},
  year={2016},
  url={https://arxiv.org/pdf/1607.07330.pdf},
  organization={IEEE}
}

@article{defferrard2016convolutional,
  title={Convolutional neural networks on graphs with fast localized spectral filtering},
  author={Defferrard, Micha{\"e}l and Bresson, Xavier and Vandergheynst, Pierre},
  journal={Advances in neural information processing systems},
  volume={29},
  url={https://proceedings.neurips.cc/paper/2016/file/04df4d434d481c5bb723be1b6df1ee65-Paper.pdf},
  year={2016}
}

@article{kipf2016semi,
  title={Semi-supervised classification with graph convolutional networks},
  author={Kipf, Thomas N and Welling, Max},
  journal={arXiv preprint arXiv:1609.02907},
  url={https://arxiv.org/pdf/1609.02907v4.pdf},
  year={2016}
}

@article{scarselli2008graph,
  title={The graph neural network model},
  author={Scarselli, Franco and Gori, Marco and Tsoi, Ah Chung and Hagenbuchner, Markus and Monfardini, Gabriele},
  journal={IEEE transactions on neural networks},
  volume={20},
  number={1},
  pages={61--80},
  year={2008},
  url={https://persagen.com/files/misc/scarselli2009graph.pdf},
  publisher={IEEE}
}

@inproceedings{seo2018structured,
  title={Structured sequence modeling with graph convolutional recurrent networks},
  author={Seo, Youngjoo and Defferrard, Micha{\"e}l and Vandergheynst, Pierre and Bresson, Xavier},
  booktitle={International Conference on Neural Information Processing},
  pages={362--373},
  year={2018},
  url={https://arxiv.org/pdf/1612.07659.pdf?ref=https://githubhelp.com},
  organization={Springer}
}

@article{hamilton2017inductive,
  title={Inductive representation learning on large graphs},
  author={Hamilton, Will and Ying, Zhitao and Leskovec, Jure},
  journal={Advances in neural information processing systems},
  volume={30},
  url={https://cs.stanford.edu/people/jure/pubs/graphsage-nips17.pdf},
  year={2017}
}

@inproceedings{xu2019generative,
  title={Generative graph convolutional network for growing graphs},
  author={Xu, Da and Ruan, Chuanwei and Motwani, Kamiya and Korpeoglu, Evren and Kumar, Sushant and Achan, Kannan},
  booktitle={ICASSP 2019-2019 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},
  pages={3167--3171},
  year={2019},
  url={https://sci-hub.se/10.1109/icassp.2019.8682360},
  organization={IEEE}
}

@article{kipf2016variational,
  title={Variational graph auto-encoders},
  author={Kipf, Thomas N and Welling, Max},
  journal={arXiv preprint arXiv:1611.07308},
  url={https://arxiv.org/pdf/1611.07308.pdf%5D},
  year={2016}
}

@inproceedings{qu2020continuous,
  title={Continuous-time link prediction via temporal dependent graph neural network},
  author={Qu, Liang and Zhu, Huaisheng and Duan, Qiqi and Shi, Yuhui},
  booktitle={Proceedings of The Web Conference 2020},
  pages={3026--3032},
  url={https://sci-hub.se/10.1145/3366423.3380073},
  year={2020}
}

@article{vaswani2017attention,
  title={Attention is all you need},
  author={Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N and Kaiser, {\L}ukasz and Polosukhin, Illia},
  journal={Advances in neural information processing systems},
  volume={30},
  url={https://arxiv.org/pdf/1706.03762.pdf},
  year={2017}
}
