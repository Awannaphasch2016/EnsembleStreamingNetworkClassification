#+TITLE: Ensemble Approaches for Streaming Networking Classification
#+DATE: <2022-03-03 Thu>
#+AUTHOR: Anak Wannaphaschaiyong
#+EMAIL: awannaphasch2016@fau.edu
#+OPTIONS: toc:nil
#+LATEX_CLASS: IEEE
#+latex_header: \usepackage[backend=biber, style=numeric]{biblatex}
#+latex_header: \addbibresource{reference.bib}

* Introduction
:PROPERTIES:
:ID:       32be6ae3-6af3-49d0-9edb-b2009b3f6e42
:END:
# Start to draw a system framework, which shows the complete framework of your ensemble approach for streaming graph prediction.

# What are streaming graphs (dynamic nodes, edges et.c)? what are streaming graphs applications? Why streaming graphs are important
Dynamic graph is a vaguely used term. In general, dynamic graph is an ordered list of node and link events. These events include deletion and addition of nodes and edges after a interval of time.
Dynamic graph is known in other named as streaming graph and temporal graph. Concretely, dynamic graph can be categorized into taxonomies. A few embedding dynamic network surveys have attempted to provide these taxonomies [[cite:&barrosSurveyEmbeddingDynamic2021;&kazemiRepresentationLearningDynamica;&skardingFoundationsModelingDynamic2021]].

# We will use streaming graph and dynamic graph interchangeably in the paper.
Many real world problems involve entities and their relationship. This is best represented by graph data structures. In the case where graphs evolve overtimes, dynamic graph can be used to model them. This phenomenon is observed all the time. For example, relationship between species in an ecosystem and communication between computer in distributed computing, among others.

More related to the field of machine learning, dynamic graph modeling is still under explored, but its applications has been explored more in the past few years. Reinforcement learning was used to solve graph protection problems on dynamic graph [[cite:&wijayanto2018learning;&wijayanto2019effective]]. Meirom at el. [[cite:&meirom2021controlling]] uses graph neural network to propagate information and reinforcement learning to rank highly infectious candidate. As of recently, during the Covid-19 pandemic, Kapoor et al. [[cite:&kapoor2020examining]]  applies graph neural network on mobility data, which is represented as dynamic graph data, to predict code cases.

# For static graph (no streaming or changing edges), what are typical link prediction or node classification solutions. What are challenges, if network is dynamically changing?
In static network, one must consider type of network relationship (e.g idealize network, proximity network.), scale of network (e.g. a node as a single entity, a node as a group of entities.), and network variation (e.g. homogenous network, heterogenous network, multilayer network).
The mentioned factors provide unique challenges. These factors must be considered before model designing phase starts otherwise network based models cannot be compared fairly. Moreover, it provide mental framework to guide designing process.

Dynamic graph extends static graph to include time variables. This add more degree of freedom to the problem. Additional degree of freedom include network status (how is information about network aggregated over time.), dynamic behavior on graph (communication behavior between nodes) and graph evolution. (structure,features,role evolution of a graph)

# For streaming graphs, what are analytics objective (or learning objective)? E.g., node classification, link prediction?

# What are the main motivation of the proposed research? What are the overall framework of the proposed design?
Currently, in the field of machine learning on dynamic network, simply train-test split is used to conclude models performance. This is not a good idea because dynamic network data is a sequential data. It is more appropriate to use sliding window evaluation. Sliding window evaluation is a well known technique that is a gold standard for sequential data such as time series data. Furthermore, we found that models capacity directly depends on sliding window parameters such as window size, epoch per window etc. Therefore, without adopting sliding window evaluation as a standard to evaluate performance of dynamic network, one cannot create a fair environment to compare performance between dynamic network based models.
For this reason, in this paper, we adopt window sliding window evaluation to evaluate link prediction and node classification using dynamic network as input.
The paper analyze multiple ensemble approaches which can only be adopted via sliding window evaluation. This provides another tool to be used within dynamic graph environment.

# What are brief results of the proposed design.
[What are brief results of the proposed design?] It is not yet clear to me what I should write for this.
** TODO make introduction be a full 1 page. :noexport:

* Related Work 
** Dynamic Graph
:PROPERTIES:
:ID:       13892178-9d6d-4add-8f7e-cfaf0a728a59
:END:
*** Taxonomies of Dynamic Graph
:PROPERTIES:
:ID:       5239e60b-2a9b-4766-a361-d3f983e6eeb3
:CUSTOM_ID: taxonomies of dynamic graph
:END:
# What are the types of dynamic graph?
At the time of writing many taxonomies of dynamic graph models has been proposed.
In this related work section, we will discuss previous attempts to categorize dynamic graph models into groups. Before discussing previous attempt, one should understand types of dynamic behavior that can affect dynamic graph models. There are two types of dynamic behaviors which are referred to in referenced literature by different names, nonetheless, we will refer to the two types as "dynamic behavior on graph" and "dynamic behavior over graph". One can think of dynamic behavior on graph as communication between nodes that happens via edges. Dynamic  behavior over graph can be think of as changes of graph as a whole over time. Intuitively, "dynamic behavior on graph" concerns micro (node/edges) levels while "dynamic behavior over graph" concern macro level --- concern graph as a whole. An example to emphasize on the difference, given that there exist a group of individuals, Evolution of individuals (nodes) "role" depends on when and how they interact. At the macro level, a member of a group may leave and join. This behavior also depends on time interval that experiment considers.

Furthermore, design of models directly depend on dynamic behavior involved in dynamic graph. Hence, due to the factor mentioned above, it is very important to create an environment that is fair to make comparison between dynamic graph models. In addition to factor mentioned above, there are other factors that directly influence behavior on/over a graph including size of graph, node scale, et cetera, which beyond the scope of the paper. Empirical experiment has shown that combination of factors previously mentioned produces different temporal characteristic of dynamic graph either on/over the graph e.g. business property cite:&holme2012temporal among other.

# What exactly is the differences?
# what types of taxonomies is proposed?
Barros et al. cite:&barrosSurveyEmbeddingDynamic2021 categorized dynamic graph based on output embedding, model approaches, and dynamic behavior over graph. On the other than, Kazemi et al. [[cite:&kazemiRepresentationLearningDynamica]] discuss in-depth mathematical formulation of encoder-decoder, one of many model approaches. The discussion also cover other types of models that are more specialized such as dynamic knowledge graph and spatio-temporal graph.

Skarding et al. [[cite:&skardingFoundationsModelingDynamic2021]] takes interesting approach to categorized dynamic graph based on edges duration into interaction networks, temporal networks, evolving networks, and strictly evolving networks. Futhermore, the paper classifies dynamic network models into statical models, stochastic actor oretied models, and dynamic network representation learning model. In comparison, Skarding et al. [[cite:&skardingFoundationsModelingDynamic2021]] and Kazemi et al. cite:&kazemiRepresentationLearningDynamica provides two different ways to categorize dynamic graph models. In contrast to Kazemi et al, Skarding et al. focus mainly on taxonomies of dynamic graph neural network including pseudo-dynamic model, edge-weighted model, discrete model, continuous models.

Note that meaning of temporal networks is ambiguous outside of skarding et al's paper [[cite:&skardingFoundationsModelingDynamic2021]] context. In "Temporal Network" paper, Holme et al. [[cite:&holme2012temporal]] introduce "time-respecting" path as a property of temporal network. Graph with time-respect path contains edges whose weight value represents time when edges forms. We will adopt taxonomy presented in [[cite:&skardingFoundationsModelingDynamic2021]] because including adopting temporal network definition. This is unambiguous because time-respecting path has not explored at all in the machine learning at the time of writing. Furthermore, all types of dynamic graph can be represented as a form of multilayer graph. [[cite:&kivela2014multilayer]]

**** TODO draw types of dynamic graph  :noexport:
*** Dynamic Graph Modeling
:PROPERTIES:
:ID:       5140dac5-33fb-467d-a79e-d193bd5b36f0
:END:
**** TODO list attempt to model dynamic graph. what are assumsion that each model asumme? can they be compared? :ignore:
TGN,
# should I consider control cases?  just mention that it whether it uses sliding window or not
** Sliding Window Evaluation
:PROPERTIES:
:ID:       393d96b8-e5b6-40ea-949c-d21cc3daacbb
:END:
Sliding window is the basis of how to turn any time series dataset into a supervised learning problem. Given that an instance in a dataset is a event with timestamp, train-test-split are a kind of sliding window where you only have 1 window to train to predict the future. Because temporal properties of time window depends on window size and interval of time, evaluate performance based on sliding window show model's performance under various temporal condition, hence, performance of models cannot be manipulated.

Sliding window is specially important in dynamic based graph when applying ensemble models on top of dynamic graph models, as we will show later, overall performance depends on size of window, number of epoch per window, number of windows, number of batch per window, number of window, and time budget.

Furthermore, sequence of windows allows one to apply a higher level of abstraction over sequence of events which may influence models design. In this case, sliding window evaluation must be applied to all the models involve to create a fair comparison.

In the time of writing, dynamic graph model literature still uses simple train-val-test split as a model evaluation standards. We provide examples of well accepted paper to make a point. Tian et al. [[cite:&tian2021self]] use 70-15-15 split to evaluate self-supervised learning on strictly evolving graph and compare with models. Performance of models are evaluated based on two tasks: link prediction and node classification. The comparison is limited to static graph models, and dynamic random walk. Details to extend static graph models to dynamic graphs are not discussed. Similarly, using the same dataset, Rossi et al. [[cite:&rossi2020temporal]] also use 70-15-15 splits. Rossi et al. compare its own, temporal graph neural network (TGN) to one other dynamic graph, DyRep. The comparison is acceptable because same dataset is used in the experiment. Dataset used in mentioned papers are collected as undirected interaction network.

It is very important to understand that how models receive data --- stream data, one instance at a time, or in batch --- implies underlying graph type. This is because it implies existence duration of nodes and edges which is used to classify dynamic graph based on taxonomies proposed by Skarding et al. [[cite:&skardingFoundationsModelingDynamic2021]]. For detail about taxonomies of dynamic graph can be found in [[#taxonomies of dynamic graph]] section.

To the best of my knowledge, Skarding et al. wrote "BENCHMARKING GRAPH NEURAL NETWORKS ON DYNAMIC LINK PREDICTION" cite:&skarding2021benchmarking which is the only paper to compare dynamic network based models using sliding window evaluation. Directed and undirected interaction network is used. Interaction network can be easily aggregated to form "graph snapshot." Hence, using interaction network, one can pass in continuous network to continuous model and discrete network to discrete models.

Performance of each model varies across metric score. Hence, the paper concludes that optimizing the hyperparamters is essential for obtaining a representative score. This conclusion applies for both static and dynamic graph models. Furthermore, Skarding et al. observes that using window of size 5 or 10 consistently produce best results particularly among discrete models.

*** TODO read and see if there are important detail that I can add to the paper. (benchmark paper, https://openreview.net/pdf?id=I2KAe7x67JU) :noexport:
* Approaches
:PROPERTIES:
:ID:       089297cd-a191-42fe-824e-21f3d297094b
:END:

#+NAME: parameters
#+CAPTION: Parameters symbols and descriptions
|------------------------+---------------------------+--------------------------------------------------------------|
|------------------------+---------------------------+--------------------------------------------------------------|
|                        | parameters                | description                                                  |
|------------------------+---------------------------+--------------------------------------------------------------|
| window parameters      | $w_i$                     | i-th window                                                  |
|                        | $ws$                      | window size                                                  |
|                        | $\vert w \vert$           | number of window used during training                        |
|                        | $bs$                      | batch size for a given window where $bs < ws$                |
| temporal parameters    | $stride$                  | window stride                                                |
|                        | $pred\_next_{n}$          | predict instances that are in window that is n window away.  |
|                        | $keep\_last\_n$           | number of window to keep as window slides forward            |
|                        | $total\_training_windows$ | total number of instances to be trained for                  |
| ensemble parameters    | $E_i$                     | i-th model in ensemble                                       |
|                        | $\vert E \vert$           | number of models used in ensemble                            |
|                        | $train\_w_{i}$            | i-th window is the first window to begin training            |
| granularity parameters | $PW$                      | granularity of prediction. Prediction length during training |

#+name: symbols
#+CAPTION: symbols
#+attr_html: :width 500px
[[file:./images/screenshot_20220321_130824.png]]

#+name: window_parameters
#+CAPTION: window parameters
#+attr_html: :width 500px
[[file:./images/screenshot_20220321_110302.png]]

#+name: temporal_parameters
#+CAPTION: temporal parameters
#+attr_html: :width 500px
[[file:./images/screenshot_20220321_130701.png]]

#+name: granularity_parameters
#+CAPTION: granularity parameters
#+attr_html: :width 500px
[[file:./images/screenshot_20220321_130720.png]]


In sliding window evaluation setting, one needs to make sure proposed model and benchmark model is being tested as fair as possible. Furthermore, to extract the most benefit from ensemble models, participated models should provide diverse predictive information. Table ref:parameters provides list of parameters that must be considered to maximize diversity of predictive information in ensemble models.

According to Table ref:parameters, we categorize parameters of sliding window evaluation into four categories: windows parameters, temporal parameters, ensemble parameters, and granularity parameters.
Window parameters and ensemble parameters are self-explanatory, but granularity parameters and temporal parameters need clarification.
Granularity is determined by prediction length during training. This parameter is important because it tells the model to minimize its mistake for certain time interval. In the other word, a model whose prediction performance is optimized over 10 days will be different to model whose performance is optimized over one day. Larger model that is trained on larger granularity ignores short term stochasticity of temporal dependencies. Illustration of window parameters, temporal parameters, granularity parameters groups are provided in Figure ref:window_parameters, ref:temporal_parameters, and ref:granularity_parameters. Symbols used in figures followed Figure ref:symbols.

It is important to note that temporal parameters can be applied "during ensemble formation" and "in-between ensemble formation." During ensemble formation referring to the modeling step where, given a fix set of training length, N number of individuals are trained before voting predictive score to finalize an ensemble performance. In contrast, in-between ensemble formation occurs after ensemble performance of the previous timestep is finalized and set of training instance is adjusted before it will be used to train an ensemble model of the next time step.

#+name: ensemble_variation_1
#+CAPTION: ensemble variation 1
#+attr_html: :width 500px
[[file:./images/screenshot_20220321_124235.png]]

#+name: ensemble_variation_2
#+CAPTION: ensemble variation 2
#+attr_html: :width 500px
[[file:./images/screenshot_20220321_124707.png]]

# We proposed two ways of doing ensemble which are shown in Figure ref:ensemble_variation_1 and Figure. ref:ensemble_variation_2. Let fix =predict_name_n= to be 1, Figure. ref:ensemble_variation_1 has five windows from $w_0$ to $w_4$. Ensemble variation 1 output 3

Using sliding window evaluation approach, there are a lot of combination of parameters that can effect model's predictive information. For this reason, one may consider using time budget to reduce size of solution space.

** TODO Explains how ensemble is constructed from =ensemble_variation_1= and =ensemble_variation_2= :noexport:
** TODO use pseudocode to describe.
* Dataset
:PROPERTIES:
:ID:       031487f0-84ab-4757-b3e6-e5bd4f74ded9
:END:
*Reddit dataset*: Reddit dataset are a bipartite network of interaction network involving two groups of nodes: Reddit threads and users. Row of the dataset is a tuple of including user-id, thread-id, timestamp, whether user is banned after this event, and pre-compute embedding score with 172 dimensions. There are 672448 instances of interaction (aka edges) which is collected in one month time interval with total 11,000 nodes. Property of Reddit dataset is shown in Table [[ref:Datasets]].

#+NAME: Datasets
#+CAPTION: Datasets
|----------------------------+---------|
|----------------------------+---------|
|                            | Reddit  |
|----------------------------+---------|
| # Nodes                    | 11,000  |
| # Edges                    | 672,447 |
| # Edges Features           | 172     |
| Timestapn                  | 1 month |
| positive label percentages | 0.05 %  |
* Results
** TODO read my log file and get conclusion out of it :noexport:
* Bibliography :ignore:
:PROPERTIES:
:ID:       308095ea-93bb-409e-ac4f-8da9f0d7839c
:END:
\printbibliography
